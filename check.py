import torch
import torch.nn.functional

# loss = torch.nn.CrossEntropyLoss()
# input = torch.randn(3, 5, requires_grad=True)
# target = torch.empty(3, dtype=torch.long).random_(5)
# output = loss(input, target)
# output.backward()



#x = torch.load("embedding.pt")



def sasi(x,y):
    return x,y

x, _ = sasi(1,2)
print(x)

